{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11585380,"sourceType":"datasetVersion","datasetId":7264109}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\n\n# Log in to W&B (usually called at the start of the script)\n#wandb.login()\n\n# Optionally: You can specify the API key if not logged in yet, or use environment variables for automatic login\nwandb.login(key='acdc26d2fc17a56e83ea3ae6c10e496128dee648')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:20:14.652045Z","iopub.execute_input":"2025-05-14T18:20:14.652214Z","iopub.status.idle":"2025-05-14T18:20:23.277334Z","shell.execute_reply.started":"2025-05-14T18:20:14.652193Z","shell.execute_reply":"2025-05-14T18:20:23.276650Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mviinod9\u001b[0m (\u001b[33mviinod9-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, embed_dim, hidden_dim, num_layers, cell_type='LSTM', dropout=0.2):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n\n        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n        self.rnn = rnn_cls(embed_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=False)\n        self.cell_type = cell_type\n\n    def forward(self, src):\n        embedded = self.embedding(src)\n        outputs, hidden = self.rnn(embedded)\n        return hidden  # hidden: tuple for LSTM, tensor for RNN/GRU\n\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, embed_dim, hidden_dim, num_layers, cell_type='LSTM', dropout=0.2):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n\n        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n        self.rnn = rnn_cls(embed_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=False)\n        self.fc_out = nn.Linear(hidden_dim, output_dim)\n        self.cell_type = cell_type\n\n    def forward(self, input, hidden):\n        input = input.unsqueeze(1)  # (batch, 1)\n        embedded = self.embedding(input)  # (batch, 1, embed_dim)\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.fc_out(output.squeeze(1))  # (batch, output_dim)\n        return output, hidden\n\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, enc_layers, dec_layers,\n                 cell_type='LSTM', dropout=0.2):\n        super(Seq2Seq, self).__init__()\n        self.encoder = Encoder(input_dim, embed_dim, hidden_dim, enc_layers, cell_type, dropout)\n        self.decoder = Decoder(output_dim, embed_dim, hidden_dim, dec_layers, cell_type, dropout)\n        self.cell_type = cell_type\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size, trg_len = trg.size()\n        outputs = torch.zeros(batch_size, trg_len, self.decoder.fc_out.out_features, device=src.device)\n\n        hidden = self.encoder(src)\n\n        if self.cell_type == 'LSTM':\n            decoder_hidden = (hidden[0][:self.decoder.rnn.num_layers], hidden[1][:self.decoder.rnn.num_layers])\n        else:\n            decoder_hidden = hidden[:self.decoder.rnn.num_layers]\n\n        input = trg[:, 0]  # <sos>\n\n        for t in range(1, trg_len):\n            output, decoder_hidden = self.decoder(input, decoder_hidden)\n            outputs[:, t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[:, t] if teacher_force else top1\n\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:20:29.199033Z","iopub.execute_input":"2025-05-14T18:20:29.199291Z","iopub.status.idle":"2025-05-14T18:20:33.168164Z","shell.execute_reply.started":"2025-05-14T18:20:29.199272Z","shell.execute_reply":"2025-05-14T18:20:33.167379Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\n\ndef build_vocab(sequences):\n    chars = set(ch for seq in sequences for ch in seq)\n    stoi = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n    for ch in sorted(chars):\n        stoi[ch] = len(stoi)\n    itos = {i: ch for ch, i in stoi.items()}\n    return stoi, itos\n\ndef encode_sequence(seq, stoi):\n    return [stoi.get(c, stoi['<unk>']) for c in seq]\n\ndef prepare_batch(pairs, inp_stoi, out_stoi, device):\n    src_seq = [torch.tensor(encode_sequence(src, inp_stoi) + [inp_stoi['<eos>']]) for src, _ in pairs]\n    trg_seq = [torch.tensor([out_stoi['<sos>']] + encode_sequence(trg, out_stoi) + [out_stoi['<eos>']]) for _, trg in pairs]\n    src_batch = pad_sequence(src_seq, batch_first=True, padding_value=inp_stoi['<pad>'])\n    trg_batch = pad_sequence(trg_seq, batch_first=True, padding_value=out_stoi['<pad>'])\n    return src_batch.to(device), trg_batch.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:20:40.200384Z","iopub.execute_input":"2025-05-14T18:20:40.201008Z","iopub.status.idle":"2025-05-14T18:20:40.207295Z","shell.execute_reply.started":"2025-05-14T18:20:40.200982Z","shell.execute_reply":"2025-05-14T18:20:40.206402Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n#from model import Seq2Seq\n#from utils import build_vocab, prepare_batch\nimport wandb\nimport random\n\ndef read_dataset(path):\n    with open(path, encoding='utf-8') as f:\n        lines = f.read().strip().split('\\n')\n        return [(l.split('\\t')[1], l.split('\\t')[0]) for l in lines if '\\t' in l]\n\ndef calculate_accuracy(preds, targets, ignore_index=0):\n    preds = preds.argmax(dim=-1)\n    mask = targets != ignore_index\n    correct = (preds == targets) & mask\n    return correct.sum().item() / mask.sum().item()\n\ndef evaluate(model, data, src_vocab, tgt_vocab, device, criterion, batch_size):\n    model.eval()\n    total_loss = 0\n    total_acc = 0\n    with torch.no_grad():\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i + batch_size]\n            src, trg = prepare_batch(batch, src_vocab, tgt_vocab, device)\n            output = model(src, trg)\n            loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n            acc = calculate_accuracy(output[:, 1:], trg[:, 1:])\n            total_loss += loss.item()\n            total_acc += acc\n    return total_loss / len(data), total_acc / (len(data) // batch_size)\n\ndef train():\n    wandb.init(config={\n    \"embed_dim\": 128,\n    \"hidden_dim\": 256,\n    \"enc_layers\": 2,\n    \"dec_layers\": 2,\n    \"cell_type\": \"LSTM\",\n    \"dropout\": 0.2,\n    \"epochs\": 10,\n    \"batch_size\": 64})\n    config = wandb.config\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    train_data = read_dataset(\"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_data = read_dataset(\"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    src_vocab, tgt_vocab = build_vocab([src for src, _ in train_data]), build_vocab([tgt for _, tgt in train_data])\n    model = Seq2Seq(len(src_vocab[0]), len(tgt_vocab[0]), config.embed_dim, config.hidden_dim,\n                    config.enc_layers, config.dec_layers, config.cell_type, config.dropout).to(device)\n\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(config.epochs):\n        model.train()\n        total_loss = 0\n        total_acc = 0\n        random.shuffle(train_data)\n\n        for i in range(0, len(train_data), config.batch_size):\n            batch = train_data[i:i + config.batch_size]\n            src, trg = prepare_batch(batch, src_vocab[0], tgt_vocab[0], device)\n\n            optimizer.zero_grad()\n            output = model(src, trg)\n            loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n            acc = calculate_accuracy(output[:, 1:], trg[:, 1:])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            total_acc += acc\n\n        avg_train_loss = total_loss / len(train_data)\n        avg_train_acc = total_acc / (len(train_data) // config.batch_size)\n\n        val_loss, val_acc = evaluate(model, dev_data, src_vocab[0], tgt_vocab[0], device, criterion, config.batch_size)\n\n        wandb.log({\n            \"train_loss\": avg_train_loss,\n            \"train_acc\": avg_train_acc,\n            \"val_loss\": val_loss,\n            \"val_acc\": val_acc,\n            \"epoch\": epoch + 1\n        })\n\n        print(f\"Epoch {epoch + 1}/{config.epochs} | \"\n              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    wandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:20:46.132398Z","iopub.execute_input":"2025-05-14T18:20:46.132693Z","iopub.status.idle":"2025-05-14T18:20:46.145575Z","shell.execute_reply.started":"2025-05-14T18:20:46.132669Z","shell.execute_reply":"2025-05-14T18:20:46.144875Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import wandb\n#from train import train  # make sure your train function is properly imported\n\nsweep_config = {\n    'method': 'grid',\n    'metric': {\n        'name': 'loss',\n        'goal': 'minimize'\n    },\n    'parameters': {\n        'embed_dim': {'values': [32, 64, 256]},\n        'hidden_dim': {'values': [64, 128]},\n        'enc_layers': {'values': [1, 2]},\n        'dec_layers': {'values': [1, 2]},\n        'cell_type': {'values': ['LSTM', 'GRU']},\n        'dropout': {'values': [0.2, 0.3]},\n        'batch_size': {'value': 32},\n        'epochs': {'value': 10}\n    }\n}\n\nsweep_id = wandb.sweep(sweep_config, project=\"Vinod_Assignment 3\")\nwandb.agent(sweep_id, function=train, count=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:20:52.142264Z","iopub.execute_input":"2025-05-14T18:20:52.142550Z","iopub.status.idle":"2025-05-14T18:25:06.155715Z","shell.execute_reply.started":"2025-05-14T18:20:52.142528Z","shell.execute_reply":"2025-05-14T18:25:06.155198Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: z92uehik\nSweep URL: https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/sweeps/z92uehik\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 71lsww45 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250514_182058-71lsww45</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/runs/71lsww45' target=\"_blank\">autumn-sweep-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/sweeps/z92uehik' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/sweeps/z92uehik</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment%203</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/sweeps/z92uehik' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/sweeps/z92uehik</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/runs/71lsww45' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/runs/71lsww45</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 | Train Loss: 0.0833, Train Acc: 0.2958 | Val Loss: 0.0667, Val Acc: 0.3988\nEpoch 2/10 | Train Loss: 0.0561, Train Acc: 0.4763 | Val Loss: 0.0490, Val Acc: 0.5490\nEpoch 3/10 | Train Loss: 0.0448, Train Acc: 0.5706 | Val Loss: 0.0413, Val Acc: 0.6111\nEpoch 4/10 | Train Loss: 0.0390, Train Acc: 0.6235 | Val Loss: 0.0374, Val Acc: 0.6484\nEpoch 5/10 | Train Loss: 0.0355, Train Acc: 0.6591 | Val Loss: 0.0356, Val Acc: 0.6641\nEpoch 6/10 | Train Loss: 0.0333, Train Acc: 0.6800 | Val Loss: 0.0342, Val Acc: 0.6821\nEpoch 7/10 | Train Loss: 0.0314, Train Acc: 0.6983 | Val Loss: 0.0329, Val Acc: 0.6944\nEpoch 8/10 | Train Loss: 0.0302, Train Acc: 0.7093 | Val Loss: 0.0318, Val Acc: 0.7012\nEpoch 9/10 | Train Loss: 0.0291, Train Acc: 0.7203 | Val Loss: 0.0310, Val Acc: 0.7082\nEpoch 10/10 | Train Loss: 0.0280, Train Acc: 0.7304 | Val Loss: 0.0301, Val Acc: 0.7169\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.73038</td></tr><tr><td>train_loss</td><td>0.02803</td></tr><tr><td>val_acc</td><td>0.71686</td></tr><tr><td>val_loss</td><td>0.03009</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">autumn-sweep-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/runs/71lsww45' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment%203/runs/71lsww45</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment%203' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250514_182058-71lsww45/logs</code>"},"metadata":{}}],"execution_count":5}]}