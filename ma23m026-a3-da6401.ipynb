{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11585380,"sourceType":"datasetVersion","datasetId":7264109}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Encoder class\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, cell_type='RNN'):\n        super(Encoder, self).__init__()\n        \n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        \n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(emb_dim, hidden_dim, n_layers, batch_first=True)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, batch_first=True)\n        else:\n            raise ValueError(\"Invalid cell type. Choose from 'RNN', 'LSTM', or 'GRU'.\")\n            \n        self.cell_type = cell_type\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n    def forward(self, src):\n        embedded = self.embedding(src)\n        outputs, hidden = self.rnn(embedded)\n        return hidden\n\n\n# Decoder class\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, cell_type='RNN'):\n        super(Decoder, self).__init__()\n\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        \n        if cell_type == 'RNN':\n            self.rnn = nn.RNN(emb_dim, hidden_dim, n_layers, batch_first=True)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, batch_first=True)\n        else:\n            raise ValueError(\"Invalid cell type. Choose from 'RNN', 'LSTM', or 'GRU'.\")\n        \n        self.fc_out = nn.Linear(hidden_dim, output_dim)\n        self.cell_type = cell_type\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n    def forward(self, input, hidden):\n        input = input.unsqueeze(1)  # [batch_size, 1]\n        embedded = self.embedding(input)\n        output, hidden = self.rnn(embedded, hidden)\n        prediction = self.fc_out(output.squeeze(1))\n        return prediction, hidden\n\n\n# Seq2Seq wrapper\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        assert encoder.hidden_dim == decoder.hidden_dim, \"Hidden dimensions must match!\"\n        assert encoder.n_layers == decoder.n_layers, \"Number of layers must match!\"\n        assert encoder.cell_type == decoder.cell_type, \"Cell types must match!\"\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        trg_len = trg.size(1)\n        trg_vocab_size = self.decoder.fc_out.out_features\n\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n\n        hidden = self.encoder(src)\n\n        input = trg[:,0]  # Start with <sos> token\n\n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden)\n            outputs[:, t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[:, t] if teacher_force else top1\n\n        return outputs\n\n\n# Example of how to initialize\nINPUT_DIM = 100   # Size of Latin vocab\nOUTPUT_DIM = 100  # Size of Devanagari vocab\nEMB_DIM = 64\nHIDDEN_DIM = 128\nN_LAYERS = 1\nCELL_TYPE = 'LSTM'  # Choose 'RNN', 'LSTM' or 'GRU'\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nencoder = Encoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, N_LAYERS, CELL_TYPE)\ndecoder = Decoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, N_LAYERS, CELL_TYPE)\nmodel = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n\nprint(model)\n\n# Define optimizer and loss\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index=0)  # Assuming padding_idx=0\n\n# Ready for training loop!\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:55:23.180202Z","iopub.execute_input":"2025-04-27T08:55:23.180458Z","iopub.status.idle":"2025-04-27T08:55:32.341276Z","shell.execute_reply.started":"2025-04-27T08:55:23.180438Z","shell.execute_reply":"2025-04-27T08:55:32.340373Z"}},"outputs":[{"name":"stdout","text":"Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (rnn): LSTM(64, 128, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (rnn): LSTM(64, 128, batch_first=True)\n    (fc_out): Linear(in_features=128, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}