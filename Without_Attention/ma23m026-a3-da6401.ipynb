{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11585380,"sourceType":"datasetVersion","datasetId":7264109}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# New","metadata":{}},{"cell_type":"code","source":"import wandb\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nfrom torch.nn.utils.rnn import pad_sequence\n\n# Log in to W&B\nwandb.login(key='acdc26d2fc17a56e83ea3ae6c10e496128dee648')\n\n# ---------- Model Definitions ----------\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, embed_dim, hidden_dim, num_layers, cell_type='LSTM', dropout=0.2, bidirectional=False):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n        self.rnn = rnn_cls(embed_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional\n\n    def forward(self, src):\n        embedded = self.embedding(src)\n        outputs, hidden = self.rnn(embedded)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, embed_dim, hidden_dim, num_layers, cell_type='LSTM', dropout=0.2, bidirectional=False):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n        self.rnn = rnn_cls(embed_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n        self.fc_out = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional\n\n    def forward(self, input, hidden):\n        input = input.unsqueeze(1)\n        embedded = self.embedding(input)\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.fc_out(output.squeeze(1))\n        return output, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, enc_layers, dec_layers,\n                 cell_type='LSTM', dropout=0.2, bidirectional=False):\n        super(Seq2Seq, self).__init__()\n        self.encoder = Encoder(input_dim, embed_dim, hidden_dim, enc_layers, cell_type, dropout, bidirectional)\n        self.decoder = Decoder(output_dim, embed_dim, hidden_dim, dec_layers, cell_type, dropout, bidirectional)\n        self.cell_type = cell_type\n\n    # ✔ Add this inside the class\n    def adjust_hidden_for_decoder(self, encoder_hidden):\n        enc_layers = self.encoder.rnn.num_layers\n        dec_layers = self.decoder.rnn.num_layers\n\n        def adjust(h):\n            if enc_layers == dec_layers:\n                return h\n            elif enc_layers < dec_layers:\n                repeat_h = h[-1].unsqueeze(0).repeat(dec_layers - enc_layers, 1, 1)\n                return torch.cat([h, repeat_h], dim=0)\n            else:\n                return h[-dec_layers:]\n\n        if self.cell_type == 'LSTM':\n            h, c = encoder_hidden\n            h = adjust(h)\n            c = adjust(c)\n            return (h, c)\n        else:\n            h = encoder_hidden\n            h = adjust(h)\n            return h\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size, trg_len = trg.size()\n        outputs = torch.zeros(batch_size, trg_len, self.decoder.fc_out.out_features, device=src.device)\n    \n        hidden = self.encoder(src)\n        # ✔ Use the adjusted hidden\n        decoder_hidden = self.adjust_hidden_for_decoder(hidden)\n    \n        input = trg[:, 0]\n        for t in range(1, trg_len):\n            output, decoder_hidden = self.decoder(input, decoder_hidden)\n            outputs[:, t] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[:, t] if teacher_force else top1\n    \n        return outputs\n\n\n\n# ---------- Utility Functions ----------\ndef build_vocab(sequences):\n    chars = set(ch for seq in sequences for ch in seq)\n    stoi = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n    for ch in sorted(chars):\n        stoi[ch] = len(stoi)\n    itos = {i: ch for ch, i in stoi.items()}\n    return stoi, itos\n\ndef encode_sequence(seq, stoi):\n    return [stoi.get(c, stoi['<unk>']) for c in seq]\n\ndef prepare_batch(pairs, inp_stoi, out_stoi, device):\n    src_seq = [torch.tensor(encode_sequence(src, inp_stoi) + [inp_stoi['<eos>']]) for src, _ in pairs]\n    trg_seq = [torch.tensor([out_stoi['<sos>']] + encode_sequence(trg, out_stoi) + [out_stoi['<eos>']]) for _, trg in pairs]\n    src_batch = pad_sequence(src_seq, batch_first=True, padding_value=inp_stoi['<pad>'])\n    trg_batch = pad_sequence(trg_seq, batch_first=True, padding_value=out_stoi['<pad>'])\n    return src_batch.to(device), trg_batch.to(device)\n\ndef read_dataset(path):\n    with open(path, encoding='utf-8') as f:\n        lines = f.read().strip().split('\\n')\n        return [(l.split('\\t')[1], l.split('\\t')[0]) for l in lines if '\\t' in l]\n\ndef calculate_word_accuracy(preds, targets, ignore_index=0):\n    # Get the token predictions\n    preds = preds.argmax(dim=-1)  # [batch, seq_len]\n    \n    # Create a mask where targets are not padding\n    mask = targets != ignore_index\n\n    # For word-level accuracy, we check if the entire sequence matches\n    # First, apply mask to both preds and targets\n    preds_masked = preds * mask\n    targets_masked = targets * mask\n\n    # Now compare entire sequences\n    # (preds == targets) -> shape [batch, seq_len]\n    # .all(dim=1) -> True if all tokens match for a sequence\n    sequence_correct = (preds_masked == targets_masked).all(dim=1)\n    \n    # Calculate word accuracy\n    word_accuracy = sequence_correct.float().mean().item() * 100\n\n    # print(f\"Word-level Correct Sequences: {sequence_correct.sum().item()}/{sequence_correct.size(0)}\")\n    return word_accuracy\n\ndef evaluate(model, data, src_vocab, tgt_vocab, device, criterion, batch_size):\n    model.eval()\n    total_loss = 0\n    total_acc = 0\n    with torch.no_grad():\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i + batch_size]\n            src, trg = prepare_batch(batch, src_vocab, tgt_vocab, device)\n            output = model(src, trg)\n            loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n            # Updated to word-level accuracy\n            acc = calculate_word_accuracy(output[:, 1:], trg[:, 1:])\n            total_loss += loss.item()\n            total_acc += acc\n\n    return total_loss / len(data), total_acc / (len(data) // batch_size)\n\n# ---------- Train Function ----------\n\n\ndef train():\n    wandb.init(config={\n        \"embed_dim\": 128,\n        \"hidden_dim\": 256,\n        \"enc_layers\": 2,\n        \"dec_layers\": 2,\n        \"cell_type\": \"LSTM\",\n        \"dropout\": 0.2,\n        \"epochs\": 10,\n        \"batch_size\": 64,\n        \"bidirectional\": False,\n        \"learning_rate\": 0.001,\n        \"optimizer\": \"adam\",\n        \"teacher_forcing_ratio\": 0.5,\n        \"beam_width\": 1\n    })\n    config = wandb.config\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    train_data = read_dataset(\"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_data = read_dataset(\"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    src_vocab, tgt_vocab = build_vocab([src for src, _ in train_data]), build_vocab([tgt for _, tgt in train_data])\n    model = Seq2Seq(len(src_vocab[0]), len(tgt_vocab[0]), config.embed_dim, config.hidden_dim,\n                    config.enc_layers, config.dec_layers, config.cell_type, config.dropout, config.bidirectional).to(device)\n\n    if config.optimizer == \"adam\":\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n    elif config.optimizer == \"nadam\":\n        optimizer = optim.NAdam(model.parameters(), lr=config.learning_rate)\n    else:\n        raise ValueError(\"Unsupported optimizer\")\n\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(config.epochs):\n        model.train()\n        total_loss = 0\n        total_acc = 0\n        random.shuffle(train_data)\n        # print(len(train_data))\n        for i in range(0, len(train_data), config.batch_size):\n            batch = train_data[i:i + config.batch_size]\n            src, trg = prepare_batch(batch, src_vocab[0], tgt_vocab[0], device)\n            # print(src)\n            # print(trg)\n            \n            optimizer.zero_grad()\n            output = model(src, trg, teacher_forcing_ratio=config.teacher_forcing_ratio)\n            loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n            # print('output',output.shape)   # output torch.Size([32, 13, 67])\n            # print('trg',trg.shape) # trg torch.Size([32, 13])\n            acc = calculate_word_accuracy(output[:, 1:], trg[:, 1:])\n            # print(acc)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            total_acc += acc\n\n        avg_train_loss = total_loss / len(train_data)\n        avg_train_acc = total_acc / (len(train_data) // config.batch_size)\n        val_loss, val_acc = evaluate(model, dev_data, src_vocab[0], tgt_vocab[0], device, criterion, config.batch_size)\n\n        wandb.log({\n            \"Train Loss\": avg_train_loss,\n            \"Train Accuracy\": avg_train_acc,\n            \"Validation Loss\": val_loss,\n            \"Validation Accuracy\": val_acc,\n            \"Epoch\": epoch + 1,\n            \"Learning Rate\": config.learning_rate,\n            \"Teacher Forcing Ratio\": config.teacher_forcing_ratio,\n            \"Optimizer\": config.optimizer,\n            \"Bidirectional\": config.bidirectional,\n            \"Beam Width\": config.beam_width\n        })\n\n        print(f\"Epoch {epoch + 1}/{config.epochs} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n\n    wandb.finish()\n\n# ---------- Sweep Setup ----------\nsweep_config = {\n    'method': 'random',\n    'metric': {'name': 'Validation Loss', 'goal': 'minimize'},\n    'parameters': {\n        'embed_dim': {'values': [32, 64, 256]},\n        'hidden_dim': {'values': [64, 128]},\n        'enc_layers': {'values': [3]},\n        'dec_layers': {'values': [1]},\n        'cell_type': {'values': ['LSTM']},\n        'dropout': {'values': [0.2, 0.3]},\n        'batch_size': {'value': 32},\n        'epochs': {'value': 1},\n        'bidirectional': {'values': [False]},\n        'learning_rate': {'values': [0.001, 0.002, 0.0001]},\n        'optimizer': {'values': ['adam', 'nadam']},\n        'teacher_forcing_ratio': {'values': [0.2, 0.5, 0.7]},\n        'beam_width': {'values': [1, 3, 5]}\n    }\n}\n# LSTM , GRU, RNN 1 3\n# sweep_id = wandb.sweep(sweep_config, project=\"Vinod_Assignment_3_new\")\n# wandb.agent(sweep_id, function=train, count=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T12:29:42.130794Z","iopub.execute_input":"2025-05-17T12:29:42.131674Z","iopub.status.idle":"2025-05-17T12:29:58.351290Z","shell.execute_reply.started":"2025-05-17T12:29:42.131641Z","shell.execute_reply":"2025-05-17T12:29:58.349958Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mviinod9\u001b[0m (\u001b[33mviinod9-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndef calculate_word_accuracy_from_ids(preds_ids, targets_ids, ignore_index=0):\n    \"\"\"\n    Calculates word-level accuracy given token id tensors directly (both of shape [batch, seq_len]).\n    \"\"\"\n    # Create mask where targets are not padding\n    mask = targets_ids != ignore_index\n\n    # Mask both predictions and targets\n    preds_masked = preds_ids * mask\n    targets_masked = targets_ids * mask\n\n    # Compare entire sequences: True if all tokens match in a sequence\n    sequence_correct = (preds_masked == targets_masked).all(dim=1)\n\n    # Calculate word accuracy\n    word_accuracy = sequence_correct.float().mean().item() * 100\n\n    return word_accuracy\n\n# def predict_and_log_test_examples(model, test_path, src_vocab, tgt_vocab, device, num_examples=50):\n#     model.eval()\n#     itos = tgt_vocab[1]\n#     stoi = src_vocab[0]\n\n#     test_data = read_dataset(test_path)\n#     examples = random.sample(test_data, num_examples)\n#     predictions_log = []\n\n#     preds_list = []\n#     trgs_list = []\n\n#     for src_text, tgt_text in examples:\n#         src_tensor = torch.tensor(encode_sequence(src_text, stoi) + [stoi['<eos>']], device=device).unsqueeze(0)\n        \n#         hidden = model.encoder(src_tensor)\n#         decoder_hidden = model.adjust_hidden_for_decoder(hidden)\n\n#         input = torch.tensor([tgt_vocab[0]['<sos>']], device=device)\n\n#         decoded_tokens = []\n#         for _ in range(30):  # max decoding length\n#             output, decoder_hidden = model.decoder(input, decoder_hidden)\n#             top1 = output.argmax(1)\n#             if top1.item() == tgt_vocab[0]['<eos>']:\n#                 break\n#             decoded_tokens.append(top1.item())\n#             input = top1\n\n#         prediction = decoded_tokens\n\n#         pred_str = ''.join([itos[idx] for idx in prediction])\n#         print(f\"Input: {src_text} | Target: {tgt_text} | Prediction: {pred_str}\")\n#         predictions_log.append(wandb.Html(f\"<b>Input:</b> {src_text} &nbsp; <b>Target:</b> {tgt_text} &nbsp; <b>Pred:</b> {pred_str}\"))\n\n#         tgt_encoded = [tgt_vocab[0].get(ch, tgt_vocab[0]['<unk>']) for ch in tgt_text] + [tgt_vocab[0]['<eos>']]\n#         preds_list.append(torch.tensor(prediction, device=device))\n#         trgs_list.append(torch.tensor(tgt_encoded, device=device))\n\n#     # Find the max sequence length among both preds and trgs\n#     max_len = max(max([p.size(0) for p in preds_list]), max([t.size(0) for t in trgs_list]))\n\n#     # Pad both preds and targets to max_len\n#     preds_padded = pad_sequence([torch.cat([p, torch.full((max_len - p.size(0),), 0, device=device)]) if p.size(0) < max_len else p for p in preds_list], batch_first=True)\n#     trgs_padded = pad_sequence([torch.cat([t, torch.full((max_len - t.size(0),), 0, device=device)]) if t.size(0) < max_len else t for t in trgs_list], batch_first=True)\n\n#     # Calculate word accuracy\n#     # print(preds_padded.shape)\n#     # print(trgs_padded.shape)\n#     test_word_acc = calculate_word_accuracy_from_ids(preds_padded, trgs_padded)\n\n#     print(f\"Test Word Accuracy on {num_examples} examples: {test_word_acc:.2f}%\")\n\n#     wandb.log({\n#         \"Test Predictions\": wandb.Html(\"<br>\".join([str(p) for p in predictions_log])),\n#         \"Test Word Accuracy\": test_word_acc\n#     })\n\n\ndef predict_and_log_test_examples_with_csv(model, test_path, src_vocab, tgt_vocab, device, num_examples=50, csv_save_path=\"predictions.csv\"):\n    model.eval()\n    itos = tgt_vocab[1]\n    stoi = src_vocab[0]\n\n    test_data = read_dataset(test_path)\n    examples = random.sample(test_data, num_examples)\n    predictions_log = []\n\n    preds_list = []\n    trgs_list = []\n\n    # ✅ Create a list to store for CSV\n    csv_data = []\n\n    for src_text, tgt_text in examples:\n        src_tensor = torch.tensor(encode_sequence(src_text, stoi) + [stoi['<eos>']], device=device).unsqueeze(0)\n        \n        hidden = model.encoder(src_tensor)\n        decoder_hidden = model.adjust_hidden_for_decoder(hidden)\n\n        input = torch.tensor([tgt_vocab[0]['<sos>']], device=device)\n\n        decoded_tokens = []\n        for _ in range(30):\n            output, decoder_hidden = model.decoder(input, decoder_hidden)\n            top1 = output.argmax(1)\n            if top1.item() == tgt_vocab[0]['<eos>']:\n                break\n            decoded_tokens.append(top1.item())\n            input = top1\n\n        prediction = decoded_tokens\n        pred_str = ''.join([itos[idx] for idx in prediction])\n\n        print(f\"Input: {src_text} | Target: {tgt_text} | Prediction: {pred_str}\")\n        \n        # ✅ Append data for CSV\n        csv_data.append({\n            \"Input\": src_text,\n            \"Target\": tgt_text,\n            \"Prediction\": pred_str\n        })\n\n        predictions_log.append(wandb.Html(f\"<b>Input:</b> {src_text} &nbsp; <b>Target:</b> {tgt_text} &nbsp; <b>Pred:</b> {pred_str}\"))\n\n        tgt_encoded = [tgt_vocab[0].get(ch, tgt_vocab[0]['<unk>']) for ch in tgt_text] + [tgt_vocab[0]['<eos>']]\n        preds_list.append(torch.tensor(prediction, device=device))\n        trgs_list.append(torch.tensor(tgt_encoded, device=device))\n    # Find the max sequence length among both preds and trgs\n    max_len = max(max([p.size(0) for p in preds_list]), max([t.size(0) for t in trgs_list]))\n\n    # Pad both preds and targets to max_len\n    preds_padded = pad_sequence([torch.cat([p, torch.full((max_len - p.size(0),), 0, device=device)]) if p.size(0) < max_len else p for p in preds_list], batch_first=True)\n    trgs_padded = pad_sequence([torch.cat([t, torch.full((max_len - t.size(0),), 0, device=device)]) if t.size(0) < max_len else t for t in trgs_list], batch_first=True)\n\n    # Calculate word accuracy\n    # print(preds_padded.shape)\n    # print(trgs_padded.shape)\n    test_word_acc = calculate_word_accuracy_from_ids(preds_padded, trgs_padded)\n\n    print(f\"Test Word Accuracy on {num_examples} examples: {test_word_acc:.2f}%\")\n\n    wandb.log({\n        \"Test Predictions\": wandb.Html(\"<br>\".join([str(p) for p in predictions_log])),\n        \"Test Word Accuracy\": test_word_acc\n    })\n\n    # ✅ Save to CSV\n    df = pd.DataFrame(csv_data)\n    df.to_csv(csv_save_path, index=False)\n    print(f\"✅ Saved predictions to {csv_save_path}\")\n\n\n\ndef train_pred():\n    wandb.init(config={\n        \"embed_dim\": 128,\n        \"hidden_dim\": 256,\n        \"enc_layers\": 2,\n        \"dec_layers\": 2,\n        \"cell_type\": \"LSTM\",\n        \"dropout\": 0.2,\n        \"epochs\": 10,\n        \"batch_size\": 64,\n        \"bidirectional\": False,\n        \"learning_rate\": 0.001,\n        \"optimizer\": \"adam\",\n        \"teacher_forcing_ratio\": 0.5,\n        \"beam_width\": 1\n    })\n    config = wandb.config\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    train_data = read_dataset(\"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_data = read_dataset(\"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    src_vocab, tgt_vocab = build_vocab([src for src, _ in train_data]), build_vocab([tgt for _, tgt in train_data])\n    model = Seq2Seq(len(src_vocab[0]), len(tgt_vocab[0]), config.embed_dim, config.hidden_dim,\n                    config.enc_layers, config.dec_layers, config.cell_type, config.dropout, config.bidirectional).to(device)\n\n    if config.optimizer == \"adam\":\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n    elif config.optimizer == \"nadam\":\n        optimizer = optim.NAdam(model.parameters(), lr=config.learning_rate)\n    else:\n        raise ValueError(\"Unsupported optimizer\")\n\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(config.epochs):\n        model.train()\n        total_loss = 0\n        total_acc = 0\n        random.shuffle(train_data)\n        # print(len(train_data))\n        for i in range(0, len(train_data), config.batch_size):\n            batch = train_data[i:i + config.batch_size]\n            src, trg = prepare_batch(batch, src_vocab[0], tgt_vocab[0], device)\n            # print(src)\n            # print(trg)\n            \n            optimizer.zero_grad()\n            output = model(src, trg, teacher_forcing_ratio=config.teacher_forcing_ratio)\n            loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n            # print('output',output.shape)   # output torch.Size([32, 13, 67])\n            # print('trg',trg.shape) # trg torch.Size([32, 13])\n            acc = calculate_word_accuracy(output[:, 1:], trg[:, 1:])\n            # print(acc)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            total_acc += acc\n\n        avg_train_loss = total_loss / len(train_data)\n        avg_train_acc = total_acc / (len(train_data) // config.batch_size)\n        val_loss, val_acc = evaluate(model, dev_data, src_vocab[0], tgt_vocab[0], device, criterion, config.batch_size)\n\n        wandb.log({\n            \"Train Loss\": avg_train_loss,\n            \"Train Accuracy\": avg_train_acc,\n            \"Validation Loss\": val_loss,\n            \"Validation Accuracy\": val_acc,\n            \"Epoch\": epoch + 1,\n            \"Learning Rate\": config.learning_rate,\n            \"Teacher Forcing Ratio\": config.teacher_forcing_ratio,\n            \"Optimizer\": config.optimizer,\n            \"Bidirectional\": config.bidirectional,\n            \"Beam Width\": config.beam_width\n        })\n\n        print(f\"Epoch {epoch + 1}/{config.epochs} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n        # At the end of train()\n    test_path = \"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n    # predict_and_log_test_examples(model, test_path, src_vocab, tgt_vocab, device)\n    predict_and_log_test_examples_with_csv(model, test_path, src_vocab, tgt_vocab, device, num_examples=50, csv_save_path=\"predictions_attention.csv\")\n\n    \n    wandb.finish()\n\n# ---------- Sweep Setup ----------\nsweep_config = {\n    'method': 'random',\n    'metric': {'name': 'Validation Loss', 'goal': 'minimize'},\n    'parameters': {\n        'embed_dim': {'values': [256]},\n        'hidden_dim': {'values': [128]},\n        'enc_layers': {'values': [3]},\n        'dec_layers': {'values': [1]},\n        'cell_type': {'values': ['LSTM']},\n        'dropout': {'values': [0.3]},\n        'batch_size': {'value': 32},\n        'epochs': {'value': 1},\n        'bidirectional': {'values': [False]},\n        'learning_rate': {'values': [0.001]},\n        'optimizer': {'values': ['adam']},\n        'teacher_forcing_ratio': {'values': [0.2]},\n        'beam_width': {'values': [1]}\n    }\n}\n# LSTM , GRU, RNN 1 3\nsweep_id = wandb.sweep(sweep_config, project=\"Vinod_Assignment_3_new\")\nwandb.agent(sweep_id, function=train_pred, count=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T12:33:42.301991Z","iopub.execute_input":"2025-05-17T12:33:42.302532Z","iopub.status.idle":"2025-05-17T12:35:40.988806Z","shell.execute_reply.started":"2025-05-17T12:33:42.302497Z","shell.execute_reply":"2025-05-17T12:35:40.987520Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 77bdkd1w\nSweep URL: https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/sweeps/77bdkd1w\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: imt6v769 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250517_123350-imt6v769</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/runs/imt6v769' target=\"_blank\">faithful-sweep-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/sweeps/77bdkd1w' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/sweeps/77bdkd1w</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/sweeps/77bdkd1w' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/sweeps/77bdkd1w</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/runs/imt6v769' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/runs/imt6v769</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/1 | Train Loss: 0.0816, Train Acc: 0.34% | Val Loss: 0.0564, Val Acc: 2.17%\nInput: kapdon | Target: कपड़ो | Prediction: कपपुं\nInput: bhooli | Target: भूली | Prediction: भुलि\nInput: angkor | Target: अंकोर | Prediction: अनुक्र\nInput: paathyakram | Target: पाठ्यक्रम | Prediction: पा्त्त्रर\nInput: pammi | Target: पम्मी | Prediction: पाममी\nInput: divyata | Target: दिव्यता | Prediction: दिवावाा\nInput: ear | Target: इअर | Prediction: अर्\nInput: lanset | Target: लैंसेट | Prediction: लास्स\nInput: siera | Target: सिएरा | Prediction: स्टी\nInput: anuprayogon | Target: अनुप्रयोगों | Prediction: अनुर््ुनों\nInput: chauka | Target: चौका | Prediction: चुका\nInput: mejbani | Target: मेज़बानी | Prediction: मिज्जी\nInput: bhrantiyan | Target: भ्रांतियां | Prediction: भ्र्यियों\nInput: entone | Target: एंटोन | Prediction: इंट्टन\nInput: eliminator | Target: एलिमिनेटर | Prediction: लिमिलामिय\nInput: flin | Target: फ्लिन | Prediction: फिलि\nInput: garibi | Target: गरीबी | Prediction: जार्ि\nInput: alnkaron | Target: अलंकारों | Prediction: अल्र्को\nInput: saturday | Target: सेटरडे | Prediction: स्््््य\nInput: bhavanaon | Target: भावनाओं | Prediction: भावान\nInput: january | Target: जनवरी | Prediction: जननाार\nInput: fisla | Target: फिसला | Prediction: फेलिस\nInput: malar | Target: मलार | Prediction: माला\nInput: helper | Target: हेल्पर | Prediction: हिल्ट\nInput: borivali | Target: बोरीवली | Prediction: ब्र््लि\nInput: conjunction | Target: कंजंक्शन | Prediction: कोंक्यियों\nInput: bechate | Target: बेचते | Prediction: बिचित\nInput: swa | Target: स्वा | Prediction: स्व\nInput: trap | Target: ट्रैप | Prediction: त्र्\nInput: udaanaa | Target: उड़ाना | Prediction: उददाा\nInput: kurvi | Target: कर्वी | Prediction: कुर््\nInput: panter | Target: पंटर | Prediction: पा््ि\nInput: kapda | Target: कपड़ा | Prediction: कपपा\nInput: rooting | Target: रूटिंग | Prediction: रोकिकि\nInput: maharaja | Target: महाराजा | Prediction: महाराा\nInput: mezbaan | Target: मेज़बान | Prediction: मिजाद\nInput: formuley | Target: फार्मूले | Prediction: फरर्ल्लि\nInput: amanati | Target: अमानती | Prediction: अमा्यिय\nInput: mohana | Target: मोहाना | Prediction: मुग्ा\nInput: jiwan | Target: जीवन | Prediction: जिवान\nInput: trabal | Target: ट्रेबल | Prediction: त्रााल\nInput: tanta | Target: तांता | Prediction: तााा\nInput: pearson | Target: पियरसन | Prediction: प्र्रो\nInput: padrauna | Target: पडरौना | Prediction: पुर्रा\nInput: gyatavya | Target: ज्ञातव्य | Prediction: जियायााा\nInput: aagah | Target: आग़ा | Prediction: अगाा\nInput: barahmasi | Target: बारहमासी | Prediction: बररर्ाा\nInput: route | Target: रूट | Prediction: रुक्\nInput: shmil | Target: शमिल | Prediction: श्मि\nInput: duwaidhaayein | Target: दुविधाएं | Prediction: दुवादादीय\nTest Word Accuracy on 50 examples: 0.00%\n✅ Saved predictions to predictions_attention.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Beam Width</td><td>▁</td></tr><tr><td>Epoch</td><td>▁</td></tr><tr><td>Learning Rate</td><td>▁</td></tr><tr><td>Teacher Forcing Ratio</td><td>▁</td></tr><tr><td>Test Word Accuracy</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁</td></tr><tr><td>Train Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Beam Width</td><td>1</td></tr><tr><td>Bidirectional</td><td>False</td></tr><tr><td>Epoch</td><td>1</td></tr><tr><td>Learning Rate</td><td>0.001</td></tr><tr><td>Optimizer</td><td>adam</td></tr><tr><td>Teacher Forcing Ratio</td><td>0.2</td></tr><tr><td>Test Word Accuracy</td><td>0</td></tr><tr><td>Train Accuracy</td><td>0.33717</td></tr><tr><td>Train Loss</td><td>0.08158</td></tr><tr><td>Validation Accuracy</td><td>2.16759</td></tr><tr><td>Validation Loss</td><td>0.05644</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">faithful-sweep-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/runs/imt6v769' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new/runs/imt6v769</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new' target=\"_blank\">https://wandb.ai/viinod9-iitm/Vinod_Assignment_3_new</a><br>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250517_123350-imt6v769/logs</code>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}